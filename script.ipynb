{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXVD2Xc_p1h3",
        "outputId": "363781d6-1fdc-450e-ffd2-5bd97e73e39b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'exact_cognates': [('brat', 'brother'), ('cierÅ„', 'thorn'), ('gÄ™Å›', 'goose'), ('kamieÅ„', 'heaven'), ('mech', 'moss'), ('miÃ³d', 'mead'), ('mysz', 'mouse'), ('noc', 'night'), ('nos', 'nose'), ('oko', 'eye'), ('pierdzieÄ‡', 'fart'), ('piÄ™Å›Ä‡', 'fist'), ('ramiÄ™', 'arm'), ('siedem', 'seven'), ('trzoda', 'herd'), ('ucho', 'ear'), ('weÅ‚na', 'wool'), ('woda', 'water'), ('wymiÄ™', 'udder'), ('zÄ…b', 'comb'), ('ziarno', 'corn'), ('Å¼ywy', 'quick'), ('bosy', 'bare'), ('bÃ³br', 'beaver'), ('braÄ‡', 'bear'), ('brat', 'brother'), ('broda', 'beard'), ('brzoza', 'birch'), ('caÅ‚y', 'whole'), ('dwa', 'two'), ('gÄ™Å›', 'goose'), ('gnieÅ›Ä‡', 'knead'), ('jutro', 'east'), ('kÅ‚oda', 'holt'), ('kuÄ‡', 'hew'), ('Å‚ub', 'leaf'), ('maÅ‚y', 'small'), ('mazaÄ‡', 'make'), ('mech', 'moss'), ('miÃ³d', 'mead'), ('mysz', 'mouse'), ('noc', 'night'), ('nos', 'nose'), ('nowy', 'new'), ('oko', 'eye'), ('osiem', 'eight'), ('peÅ‚ny', 'full'), ('piana', 'foam'), ('piÄ…ty', 'fifth'), ('piÄ™Å›Ä‡', 'fist'), ('pÅ‚osa', 'fallow'), ('pÅ‚owy', 'fallow'), ('reÅ¼', 'rye'), ('rudy', 'red'), ('sarna', 'horn'), ('sen', 'sweven'), ('siedzieÄ‡', 'sit'), ('siostra', 'sister'), ('sÅ‚oma', 'haulm'), ('spaÄ‡', 'sweve'), ('srom', 'harm'), ('strumieÅ„', 'stream'), ('suchy', 'sear'), ('swarzyÄ‡', 'swear'), ('syn', 'son'), ('Å›nieg', 'snow'), ('Å›winia', 'swine'), ('tajaÄ‡', 'thaw'), ('trzoda', 'herd'), ('trzy', 'three'), ('ty', 'thou'), ('tysiÄ…c', 'thousand'), ('wabiÄ‡', 'weep'), ('wdowa', 'widow'), ('weÅ‚na', 'wool'), ('wieczÃ³r', 'west'), ('wilk', 'wolf'), ('wÅ‚adaÄ‡', 'wield'), ('woda', 'water'), ('wosk', 'wax'), ('zÄ…b', 'comb'), ('ziarno', 'corn'), ('zÅ‚oto', 'gold'), ('znaÄ‡', 'know'), ('Å¼arna', 'quern'), ('Å¼ona', 'quean'), ('Å¼ywy', 'quick')], 'base_cognates': [('bÃ³Å›Ä‡', 'bed'), ('dziÄ…sÅ‚o', 'tooth'), ('glina', 'clay'), ('imiÄ™', 'name'), ('iskaÄ‡', 'ask'), ('lizaÄ‡', 'lick'), ('prosiÄ™', 'farrow'), ('sarna', 'horn'), ('szerszeÅ„', 'hornet'), ('bÃ³Å›Ä‡', 'bed'), ('cÃ³rka', 'daughter'), ('czesaÄ‡', 'hair'), ('dno', 'deep'), ('dziÄ…sÅ‚o', 'tooth'), ('dziesiÄ™Ä‡', 'ten'), ('glina', 'clay'), ('gÅ‚adki', 'glad'), ('goÅ‚y', 'callow'), ('grÃ³d', 'gird'), ('imiÄ™', 'name'), ('iskaÄ‡', 'ask'), ('jabÅ‚ko', 'apple'), ('jÄ™zyk', 'tongue'), ('lizaÄ‡', 'lick'), ('Å‚apa', 'glove'), ('Å‚gaÄ‡', 'lie'), ('matka', 'mother'), ('mÄ…Å¼', 'man'), ('owca', 'ewe'), ('pieszy', 'foot'), ('pÅ‚awiÄ‡', 'flow'), ('prosiÄ™', 'farrow'), ('rÅ¼ysko', 'rye'), ('sÅ‚oÅ„ce', 'sun'), ('sto', 'hundred'), ('suka', 'hound'), ('Å›ciana', 'stone'), ('weÅ‚na', 'wool'), ('wola', 'will'), ('Å¼ebro', 'rib')], 'base_cognates_foreign': [('serce', 'heart')], 'cognate_roots': [('mleko', 'milk'), ('alfabet', 'alphabet'), ('armia', 'army'), ('buk', 'beech'), ('chleb', 'loaf'), ('dekret', 'decree'), ('integracja', 'integration'), ('intonacja', 'intonation'), ('kardiologia', 'cardiology'), ('kardynaÅ‚', 'cardinal'), ('komunia', 'communion'), ('kot', 'cat'), ('kronika', 'chronicle'), ('krysztaÅ‚', 'crystal'), ('ksiÄ…dz', 'king'), ('kupiÄ‡', 'cheap'), ('kusiÄ‡', 'choose'), ('manuskrypt', 'manuscript'), ('maszyna', 'machine'), ('muzyka', 'music'), ('opera', 'opera'), ('oÅ›', 'axis'), ('pielgrzym', 'pilgrim'), ('pieniÄ…dz', 'penny'), ('piÅ‚a', 'file'), ('pÅ‚ug', 'plough'), ('pop', 'pope'), ('post', 'fast'), ('problem', 'problem'), ('puÅ‚k', 'folk'), ('teologia', 'theology'), ('teza', 'thesis'), ('toaleta', 'toilet'), ('tragedia', 'tragedy'), ('tygrys', 'tiger'), ('tymianek', 'thyme'), ('tytuÅ‚', 'title'), ('werdykt', 'verdict')], 'exact_cognates_foreign': [('Å‚eÅ¼', 'lie'), ('moc', 'might'), ('Å‚eÅ¼', 'lie'), ('moc', 'might'), ('Å‚eÅ¼', 'lie'), ('moc', 'might')], 'cognates_derivatives': [('grÃ³b', 'grave'), ('koÅ‚o', 'wheel'), ('niÄ‡', 'needle'), ('Å¼al', 'qualm'), ('Å¼al', 'quell'), ('koÅ‚o', 'wheel'), ('niÄ‡', 'needle'), ('przyjaciel', 'friend'), ('wiatr', 'wind'), ('Å¼al', 'qualm'), ('grÃ³b', 'grave'), ('niÄ‡', 'needle'), ('siodÅ‚o', 'saddle'), ('wiatr', 'wind'), ('Å¼al', 'qualm'), ('Å¼al', 'quell')], 'loanwords': [('goÅ›Ä‡', 'guest'), ('brzeg', 'berg'), ('goÅ›Ä‡', 'guest')]}\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def classify_text(file):\n",
        "\n",
        "    pattern1 = r\"\\bP\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\s*=\\s*E\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\b\"  #exact_cognates\n",
        "    pattern2 = r\"\\bP\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\s*&\\s*E\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\b\"   #base_cognates\n",
        "    pattern3 = r\"\\bP\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\s*&\\/\\s*E\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\b\"  #base_cognates_foreign\n",
        "    pattern4 = r\"\\bP\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\s*//\\s*E\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\b\"   #loanwords\n",
        "    pattern5 = r\"\\bP\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\s*\\^\\s*E\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\b\"    #in_cognate_roots\n",
        "    pattern6 = r\"\\bP\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\s*=\\/\\s*E\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\b\" #exact_cognate_foreign\n",
        "    pattern7 = r\"\\bP\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\s*=\\^\\s*E\\s+[a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+\\b\" #cognates_derivatives\n",
        "\n",
        "\n",
        "    exact_cognates = []\n",
        "    base_cognates = []\n",
        "    base_cognates_foreign = []\n",
        "    in_cognate_roots = []\n",
        "    cognates_derivatives = []\n",
        "    loanwords = []\n",
        "    exact_cognate_foreign = []\n",
        "\n",
        "\n",
        "    with open(file, \"r\") as f:\n",
        "        content = f.readlines()\n",
        "\n",
        "   #Categorisation\n",
        "    for line in content:\n",
        "        if re.search(pattern1, line):\n",
        "          exact_cognates.append(line.strip())\n",
        "        elif re.search(pattern2, line):\n",
        "          base_cognates.append(line.strip())\n",
        "        elif re.search(pattern3, line):\n",
        "          base_cognates_foreign.append(line.strip())\n",
        "        elif re.search(pattern4, line):\n",
        "          in_cognate_roots.append(line.strip())\n",
        "        elif re.search(pattern5, line):\n",
        "          cognates_derivatives.append(line.strip())\n",
        "        elif re.search(pattern6, line):\n",
        "          loanwords.append(line.strip())\n",
        "        elif re.search(pattern7, line):\n",
        "          exact_cognate_foreign.append(line.strip())\n",
        "\n",
        "\n",
        "  #Clean and tuple\n",
        "\n",
        "    pattern_polish = r\"\\bP\\s+([a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+)\"\n",
        "    pattern_english = r\"\\bE\\s+([a-zA-Z]+)\"\n",
        "\n",
        "    exact_cognates_tuples = []\n",
        "    base_cognates_tuples = []\n",
        "    base_cognates_foreign_tuples = []\n",
        "    in_cognate_roots_tuples = []\n",
        "    cognates_derivatives_tuples = []\n",
        "    loanwords_tuples = []\n",
        "    exact_cognate_foreign_tuples = []\n",
        "\n",
        "  #1exact_cognates\n",
        "    for string in exact_cognates:\n",
        "        polish_match = re.search(pattern_polish, string)\n",
        "        english_match = re.search(pattern_english, string)\n",
        "\n",
        "        if polish_match and english_match:\n",
        "            polish_word = polish_match.group(0)\n",
        "            english_word = english_match.group(0)\n",
        "\n",
        "            exact_cognates_tuples.append((polish_word[2:], english_word[2:]))\n",
        "  #2base_cognates\n",
        "    for string in base_cognates:\n",
        "        polish_match = re.search(pattern_polish, string)\n",
        "        english_match = re.search(pattern_english, string)\n",
        "\n",
        "        if polish_match and english_match:\n",
        "            polish_word = polish_match.group(0)\n",
        "            english_word = english_match.group(0)\n",
        "\n",
        "            base_cognates_tuples.append((polish_word[2:], english_word[2:]))\n",
        "  #3base_cognates_foreign\n",
        "    for string in base_cognates_foreign:\n",
        "        polish_match = re.search(pattern_polish, string)\n",
        "        english_match = re.search(pattern_english, string)\n",
        "\n",
        "        if polish_match and english_match:\n",
        "            polish_word = polish_match.group(0)\n",
        "            english_word = english_match.group(0)\n",
        "\n",
        "            base_cognates_foreign_tuples.append((polish_word[2:], english_word[2:]))\n",
        "\n",
        "   #4loanwards\n",
        "    for string in loanwords:\n",
        "        polish_match = re.search(pattern_polish, string)\n",
        "        english_match = re.search(pattern_english, string)\n",
        "\n",
        "        if polish_match and english_match:\n",
        "            polish_word = polish_match.group(0)\n",
        "            english_word = english_match.group(0)\n",
        "\n",
        "            loanwords_tuples.append((polish_word[2:], english_word[2:]))\n",
        "\n",
        "  #5in_cognate_roots\n",
        "    for string in in_cognate_roots:\n",
        "        polish_match = re.search(pattern_polish, string)\n",
        "        english_match = re.search(pattern_english, string)\n",
        "\n",
        "        if polish_match and english_match:\n",
        "            polish_word = polish_match.group(0)\n",
        "            english_word = english_match.group(0)\n",
        "\n",
        "            in_cognate_roots_tuples.append((polish_word[2:], english_word[2:]))\n",
        "\n",
        "  #6exact_cognate_foreign\n",
        "    for string in exact_cognate_foreign:\n",
        "        polish_match = re.search(pattern_polish, string)\n",
        "        english_match = re.search(pattern_english, string)\n",
        "\n",
        "        if polish_match and english_match:\n",
        "            polish_word = polish_match.group(0)\n",
        "            english_word = english_match.group(0)\n",
        "\n",
        "            exact_cognate_foreign_tuples.append((polish_word[2:], english_word[2:]))\n",
        "\n",
        "  #7cognates_derivatives\n",
        "    for string in cognates_derivatives:\n",
        "        polish_match = re.search(pattern_polish, string)\n",
        "        english_match = re.search(pattern_english, string)\n",
        "\n",
        "        if polish_match and english_match:\n",
        "            polish_word = polish_match.group(0)\n",
        "            english_word = english_match.group(0)\n",
        "\n",
        "            cognates_derivatives_tuples.append((polish_word[2:], english_word[2:]))\n",
        "\n",
        "\n",
        "\n",
        "    # Print the list of cognates found\n",
        "    data = {\n",
        "    \"exact_cognates\": exact_cognates_tuples,\n",
        "    \"base_cognates\": base_cognates_tuples,\n",
        "    \"base_cognates_foreign\": base_cognates_foreign_tuples,\n",
        "    \"cognate_roots\": in_cognate_roots_tuples,\n",
        "    \"exact_cognates_foreign\": exact_cognate_foreign_tuples,\n",
        "    \"cognates_derivatives\": cognates_derivatives_tuples,\n",
        "    \"loanwords\": loanwords_tuples,\n",
        "    }\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cognates_data = classify_text(\"cognates.txt\")\n",
        "\n",
        "print(cognates_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\\\n",
        "import nltk\n",
        "from nltk.chat.util import Chat, reflections\n",
        "import spacy\n",
        "import requests\n",
        "from datetime import date\n",
        "import re\n",
        "import random\n",
        "\n",
        "\n",
        "# Download spaCy model\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    from spacy.cli import download\n",
        "    download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Patterns and responses for simple queries\n",
        "pairs = [\n",
        "    [r'hi|.*hello.*', ['Hello! ğŸ‘‹\\n', 'Hi there! ğŸ‘‹\\n']],\n",
        "    [r'.*how are you.*|.*what\\'s up.*', ['I am fantastic ğŸš€ğŸš€, thank you! \\n Need any help with Polish/English cognates today?\\n']],\n",
        "    [r'.*how is your day.*', ['My day is AMAZING thanks to you ğŸ«µ, thank you for asking! \\n Now, lets get cracking with these cognates!ğŸ’ªğŸ’ª\\n']],\n",
        "    [r'.*your name.*', [\"I don't have name yet ğŸ˜¿, please give your suggestions to Ania and Weronika.\\n\"]],\n",
        "    [r'.*help.*', ['Not to worry! You gott this!ğŸ’ª \\n Now, tell me how I can help. â˜ºï¸ \\n', \"I know historical linguistics is difficult, but you're not alone! ğŸ¤ \\n So, what's your question? \\n\", \"Don't worry, we can do it ğŸ’—togetherğŸ’—! \\n How can I help?\\n\"]],\n",
        "    [r'.*what can you do.*', ['I can help you find out if and how two words â€” one in English and one in Polish â€” are related, \\n or if a specific word is connected to another in our database. \\n Oh, and I also know a few jokes ğŸ˜‰. \\n']],\n",
        "    [r'.*what is the date.*', [f'Today is {str(date.today())}. Go and enjoy it ğŸ¥³\\n']],\n",
        "    [r'.*tell me a joke.*', ['Why don\\'t skeletonsğŸ’€ğŸ’€ fight each other? \\n They don\\'t have the guts! \\n ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\\n', 'What do you call fake spaghettiğŸ? \\n An impasta! \\n ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\\n']],\n",
        "    [r'.*what are cognates.*', ['ğŸ”¥SUCH a good question!ğŸ”¥ \\nTrask (2000: 62) defines them as one of two or more words or morphemes which are directly descended from a single common ancestor \\nof the languages in which the words or morphemes are found, with no borrowing.\\n']],\n",
        "    [r'.*researchers.*', ['MikoÅ‚aj RychÅ‚o ğŸ‘¨â€ğŸ“ and his loyal disciple Anna Potrykus ğŸ‘©â€ğŸ“\\n']],\n",
        "    [r'.*pieszy and foot.*', ['Suprise!ğŸ‰ Yes, they are! For more information see Potrykus 2023. \\n(shameless plugğŸ”Œ)\\n']],\n",
        "    [r'.*best programmers.*', ['That\\'s easy! Of course, Weronika PaluchğŸ¥· and Ania PotrykusğŸ¥·!\\n']],\n",
        "    [r'.*what are borrowings.*', ['ğŸ“šIn linguistics, lexical borrowing is the process\\n by which a word from one language is adapted for use in another.\\n The word that is borrowed is called \\n1ï¸âƒ£ a borrowing, \\n2ï¸âƒ£ a borrowed word, or \\n3ï¸âƒ£ a loanword.\\n']],\n",
        "    [r'.*research\\b.*|.*article.*|.*paper.*', ['You got it! Have a look at ğŸ‘‰ RychÅ‚o, MikoÅ‚aj. (2019). Contrasting Cognates in Modern Languages from a Diachronic Perspective.\\n']],\n",
        "    [r'.*why.*', ['Why not?ğŸ¤¡\\n', \"That's so obvious I thought even you'd have already figured it out.ğŸ¤¡ğŸ¤¡\\n\"]],\n",
        "    [r'.*i think.*', ['You actually think?ğŸ«¨ I\\'d never have guessed...\\nğŸ’€\\n', 'I wouldn\\'t think too hard if I were you.ğŸ˜ª\\n']],\n",
        "    [r'.*shut up.*', ['Make me.ğŸ¥±\\n', 'Getting angry at a feeble NLP assignment? Somebody\\'s losing it.ğŸ« ğŸ« \\n', 'Say that again, I dare you.ğŸ˜ˆğŸ˜ˆ\\n']],\n",
        "    [r'.*you\\'re rude.*', ['Sorry! I\\'m just kidding.ğŸ¥´\\n']],\n",
        "    [r'.*exact cognates\\b.*', ['ğŸ“šCognates that have developed from the same proto-form with no morphological changes (Exact Cognates Sensu Stricto)\\n or with stem-formative adjustments (Exact Cognates Sensu Lato)\\n']],\n",
        "    [r'.*base cognates\\b.*', ['ğŸ“šCognates in which one of the compared languages exhibits a derivative whose base occurs in the cognate language\\n']],\n",
        "    [r'.*base cognates foreign.*', ['ğŸ“šCognates in which one of the compared languages exhibits a derivative whose base occurs in the cognate language,\\n one of the comparanda displays a foreign trait\\n']],\n",
        "    [r'.*cognate roots.*', ['ğŸ“šNot cognates, but independent derivatives in both languages with cognate roots\\n']],\n",
        "    [r'.*cognates derivatives.*', ['ğŸ“šCognates which can simultaneously be considered independent derivatives\\n']],\n",
        "    [r'.*loanwords.*', ['ğŸ“šWords related by borrowing (direct or indirect, also borrowed independently from a third source)\\n']],\n",
        "    [r'.*exact cognates foreign.*', ['ğŸ“šExact cognates with a foreign trait\\n']],\n",
        "    [r'.*thank you.*|.*thanks.*', ['You got it!ğŸ¤—', 'You\\'re welcome!\\nğŸ«¡ğŸ«¡']],\n",
        "    [r'.*tell me a fun fact.*',[\"The oldest living land animal on earth \\nis a 192-year-old ğŸ¢tortoiseğŸ¢  named Jonathan.\\n\",\"Allodoxaphobia is the fear of other peopleâ€™s opinions.\\n#relatble\\n\", \"Penicillin was first called â€œmold juice.â€ğŸ¤¢ğŸ¤¢\\n\"]],\n",
        "    ]\n",
        "\n",
        "# Function to check if two words are cognates\n",
        "def are_cognates(word1, word2):\n",
        "    for key, cognates in cognates_data.items():\n",
        "        if (word1, word2) in cognates or (word2, word1) in cognates:\n",
        "            return f\"Yes, '{word1}' and '{word2}' are related. Type of relation: {key.replace('_', ' ')}.\"\n",
        "    return f\"IdkğŸ¤·, ask RychÅ‚o if '{word1}' and '{word2}' are related\"\n",
        "\n",
        "# Function to find a cognate of a provided word\n",
        "def find_related_word(word):\n",
        "    for key, cognates in cognates_data.items():\n",
        "        for pair in cognates:\n",
        "            if word in pair:\n",
        "                related_word = pair[0] if pair[1] == word else pair[1]\n",
        "                return f\"Yes, '{word}' is related to '{related_word}'. Type of relation: {key.replace('_', ' ')}.\\n\"\n",
        "    return f\"IdkğŸ¤·, ask RychÅ‚o if '{word}' is related to anything.\"\n",
        "\n",
        "# Function to provide examples of a given cognate category\n",
        "def provide_examples(category):\n",
        "    if category in cognates_data and cognates_data[category]:\n",
        "        examples = random.sample(cognates_data[category], min(3, len(cognates_data[category])))\n",
        "        formatted_examples = \", \".join([f\"'{tup[0]}' - '{tup[1]}'\" for tup in examples])\n",
        "        return f\"Here are some examples of {category.replace('_', ' ')}: {formatted_examples}.\\n\"\n",
        "    return f\"Sorry, I don't have examples for {category.replace('_', ' ')}.\\n\"\n",
        "\n",
        "# Function to extend chatbot with cognates knowledge\n",
        "def cognate_chatbot_response(user_input):\n",
        "    match = re.match(r\".*are ([a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+) and ([a-zA-Z]+) related.*\", user_input)\n",
        "    if match:\n",
        "        word1, word2 = match.groups()\n",
        "        return are_cognates(word1, word2)\n",
        "\n",
        "    # Check if one word is related to another\n",
        "    match_related = re.match(r\".*is ([a-zÄ…Ä‡Ä™Å‚Å„Ã³Å›ÅºÅ¼]+) related to anything.*\", user_input)\n",
        "    if match_related:\n",
        "        word = match_related.group(1)\n",
        "        return find_related_word(word)\n",
        "\n",
        "    match_examples = re.match(r\".*examples of (exact cognates|base cognates|base cognates foreign|cognate roots|cognates derivatives|loanwords|exact cognates foreign).*\", user_input)\n",
        "    if match_examples:\n",
        "        category = match_examples.group(1).replace(\" \", \"_\")  # Convert to dictionary key format\n",
        "        return provide_examples(category)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Main chatbot function\n",
        "def chatbot():\n",
        "    print(\"â³Chatbot: Hi! I'm a chatbot who can help you with âœ¨historical linguisticsâœ¨ and relations between words. SupercoolğŸ¤ , right? \\n When you get tired of talking to me, type 'bye' to end the chatğŸ«¡.\\n\")\n",
        "\n",
        "    chat = Chat(pairs, reflections)  # Initialize nltk's rule-based chatbot\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"â­You: \").lower()\n",
        "        print()\n",
        "\n",
        "        # Exit condition\n",
        "        if user_input == \"bye\":\n",
        "            print(\"â³Chatbot: Glad I could help! See you next time. \\n By Anna Potrykus & Weronika Paluch ğŸ‘­ğŸ» \\n (and Prof. RychÅ‚o ğŸ‘¨â€ğŸ«)\")\n",
        "            break\n",
        "\n",
        "        # Cognate-based response\n",
        "        cognate_response = cognate_chatbot_response(user_input)\n",
        "        if cognate_response:\n",
        "            print(f\"â³Chatbot: {cognate_response}\")\n",
        "            continue\n",
        "\n",
        "        # Pattern-based response\n",
        "        response = chat.respond(user_input)\n",
        "        if response:\n",
        "            print(f\"â³Chatbot: {response}\")\n",
        "            continue\n",
        "        else:\n",
        "            print(f\"â³Chatbot: Sorry, but I don't understand.\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "5SeIsyxgp6Sd",
        "outputId": "f2e82b66-c7be-4d79-9332-8720899d6c2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³Chatbot: Hi! I'm a chatbot who can help you with âœ¨historical linguisticsâœ¨ and relations between words. SupercoolğŸ¤ , right? \n",
            " When you get tired of talking to me, type 'bye' to end the chatğŸ«¡.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2b6b5c957413>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mchatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-2b6b5c957413>\u001b[0m in \u001b[0;36mchatbot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"â­You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}